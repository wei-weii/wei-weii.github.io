---
# the default layout is 'page'
icon: fas fa-info-circle
order: 4
---

# Know Wei in 30s
I am a PhD student in the [VIXI lab](https://vixi.cs.uvic.ca/), University of Victoria. My research interest span from `visualization`, `physicalization`, to `cognitive augmentation` and more generally, `interaction design`. I had an incredible time during my MSc at [ilab](https://ilab.ucalgary.ca/), University of Calgary, possibly the best experience of my academic journey. Before that, I acquired Bachelor in SouthWest JiaoTong University, Chengdu, China. 

I am a traveler who just started to make it a hobby, a programmer who is poor in algorithm, a designer who has radical ideas, a gamer who keeps trying after repeated defeats and a reader who loves history, sci-fi, fantasy, as well as Chinese classics.

You can find the my CV [here](/assets/pdf/CV.pdf) 

# Too Long to Read

## Projects

- ### Visualizing the Three Kingdoms: The Lifespan, Network, and Homeland of Heroes and Beyond
 
As an ongoing and hobby-oriented project, I am collecting and maintaining a [data sheet](https://docs.google.com/spreadsheets/d/1c7hnmNIeD9X5W6P7Wx2E4V9_g49-ShKPHRUv_ad3ozw/edit?usp=sharing) that aims to log all individuals recorded in [Sanguozhi - Records of the Three Kingdoms](https://zh.wikisource.org/wiki/%E4%B8%89%E5%9C%8B%E5%BF%97), a Chinese history classic that chronicles China's history from 180 CE to 284 CE. You can find more info about it on the [Wiki Page](https://en.wikipedia.org/wiki/Records_of_the_Three_Kingdoms). At this moment, the data sheet has more than 1500 entries. In the future, I will turn into a open-source project and maybe create a database for it.
Furthermore, I am developing a portfolio that explore the potential of employing visualization approaches (`timeline`, `network`, `map`, and more) to synthesize and extract insights from it.

- ### [Towards Autocomplete Strategies for Visualization Construction](https://doi.org/10.48550/arXiv.2308.02679)
![ The three visualization autocomplete strategies identified in our study.](https://cdn.jsdelivr.net/gh/antimelee/media-Pages/image/AutoComplete.png)


Constructive visualization uses physical data units - `tokens` -  to enable non-experts to create personalized visualizations engagingly. However, its physical nature limits efficiency and scalability. One potential solution to address this issue is autocomplete. By providing automated suggestions while still allowing for manual intervention, autocomplete can expedite visualization construction while maintaining expressivity. We conduct a speculative design study to examine how people would like to interact with a visualization authoring system that supports autocomplete. Our study identifies three types of autocomplete strategies and gains insights for designing future visualization authoring tools with autocomplete functionality. A free copy of this paper and all supplemental materials are available on our [online repository](https://osf.io/nu4z3/?view_only=594baee54d114a99ab381886fb32a126)


- ### [Design of Anthropomorphic Interfaces for Autonomous Vehicle-Pedestrian Interaction](https://dx.doi.org/10.11575/PRISM/40689)

![ The three anthropomorphic AV interfaces](https://cdn.jsdelivr.net/gh/antimelee/media-Pages/image/AnthroAV.png)

`Expressions`, `gestures`, and `body language` are fundamental to human communication. Our work explores their potential benefits and limitations within Autonomous Vehicle (AV)-pedestrian interactions. We designed three anthropomorphic interfaces for AVs: facial expressions, hand gestures, and humanoid torsos. With these designs, we contribute a preliminary design critique to understand the strengths and weaknesses of specific anthropomorphic interfaces, a realization of these AV interfaces in an immersive VR testbed which allows pedestrians to make physical crossing decisions, and an evaluation of our testbed through a user study. Our findings suggest that AV interfaces with a higher degree of human likeness receive more favourable responses from pedestrians. Additionally, interfaces which incorporate intuitive, dynamic, and unambiguous features outperform others. Our results also highlight that some anthropomorphic AV interfaces may be efficient while not necessarily guaranteeing a high level of pedestrian comfort.

- ### [Touch and Beyond: Comparing Physical and Virtual Reality Visualizations](https://doi.org/10.1109/TVCG.2020.3023336)
- 
![ The VR scene and physicalization](https://cdn.jsdelivr.net/gh/antimelee/media-Pages/image/Touch&Beyond.png)

We compare physical and virtual reality (VR) versions of simple data visualizations. We also explore how the addition of virtual annotation and filtering tools affects how viewers solve basic data analysis tasks. We report on two studies, inspired by previous examinations of data physicalizations. The first study examined differences in how viewers interact with physical hand-scale, virtual hand-scale,and virtual table-scale visualizations and the impact that the different forms had on viewer's problem solving behavior. A second study examined how interactive annotation and filtering tools might sup-port new modes of use that transcend the limitations of physical representations. Our results highlight challenges associated with virtual reality representations and hint at the potential of interactive annotation and filtering tools in VR visualizations.